#!/usr/bin/env python
# License: GPLv3 Copyright: 2024, Kovid Goyal <kovid at kovidgoyal.net>


import base64
import glob
import json
import os
import re
from contextlib import suppress
from datetime import datetime
from email.message import Message
from functools import lru_cache
from mimetypes import guess_type
from typing import NamedTuple
from urllib.error import HTTPError
from urllib.parse import urlparse, urlunparse
from urllib.request import Request, urlopen

from html5_parser import parse  # type: ignore
from lxml.html import tostring

self_path = os.path.abspath(__file__)


def resolve_href(href, base):
    purl = urlparse(href)
    if not purl.scheme:
        path = os.path.abspath(os.path.join(base, purl.path))
        purl = purl._replace(path=path, scheme='file')
    return urlunparse(purl)


def parse_content_type(raw):
    email = Message()
    email['content-type'] = raw
    params = email.get_params()
    # The first param is the mime-type the later ones are the attributes like "charset"
    return params[0][0], dict(params[1:])


class ContentType(NamedTuple):
    mime_type: str = ''
    charset: str = ''


@lru_cache(1024)
def download_resource(url):
    ct = ContentType()
    purl = urlparse(url)
    if purl.scheme in ('file', ''):
        with open(purl.path, 'rb') as f:
            mime_type = guess_type(purl.path)[0]
            return f.read(), ContentType(mime_type)
    cache_dir = os.path.expanduser('~/.cache/talks-single-file')
    os.makedirs(cache_dir, exist_ok=True)
    fname = url.encode().hex()
    cache_path = os.path.join(cache_dir, fname)
    mtime, etag, cached_ct = 0, '', None
    with suppress(FileNotFoundError):
        with open(cache_path, 'rb') as f:
            data = f.read()
            mtime = os.path.getmtime(f.fileno())
        with open(cache_path + '.content-type') as f:
            ct = cached_ct = ContentType(*json.load(f))
        with open(cache_path + '.etag') as f:
            etag = f.read()
    headers = {}
    if etag:
        headers['If-None-Match'] = etag
    if mtime:
        dt = datetime.fromtimestamp(mtime)
        headers['If-Modified-Since'] = dt.strftime('%a, %d %b %Y %H:%M:%S GMT')

    try:
        with urlopen(Request(url, headers=headers), timeout=60) as f:
            etag = f.headers.get('ETag', '')
            cth = f.headers.get('Content-Type', '')
            if cth:
                mt, params = parse_content_type(cth)
                ct = ContentType(mt, params.get('charset', ''))

            if f.getcode() == 304 and cached_ct:
                return data, cached_ct
            data = f.read()
    except HTTPError as e:
        if e.code == 304:
            return data, cached_ct or ct
        raise
    with open(cache_path, 'wb') as f:
        f.write(data)
    with open(cache_path + '.content-type', 'w') as f:
        json.dump(list(ct), f)
    if etag:
        with open(cache_path + '.etag', 'w') as f:
            f.write(etag)
    return data, ct


@lru_cache(1024)
def download_text_resource(url):
    raw, ct = download_resource(url)
    enc = ct.charset or 'utf-8'
    text = raw.decode(enc)
    return text, ct.mime_type


def download_binary_resource(url):
    raw, ct = download_resource(url)
    return raw, ct.mime_type


def newer(dest, *sources):
    try:
        mtime = os.path.getmtime(dest)
    except FileNotFoundError:
        return True
    for s in sources:
        if os.path.getmtime(s) > mtime:
            return True
    return os.path.getmtime(self_path) > mtime


@lru_cache(1024)
def url_to_data_uri(url):
    data, mime_type = download_binary_resource(url)
    b64 = base64.standard_b64encode(data).decode()
    return f'data:{mime_type};base64,{b64}'


def inline_attr(elem, attr, base):
    href = elem.get(attr)
    if href:
        url = resolve_href(href, base)
        elem.set(attr, url_to_data_uri(url))
        return True
    return False


def inline_css_urls(text, base):
    def replace(m):
        url = m.group(1)
        q = url[0]
        if q in '"\'' and url.endswith(q):
            url = url[1:-1]
        url = resolve_href(url, base)
        data = url_to_data_uri(url)
        return f'url({data})'

    return re.sub(r'''url\(([^)]+)\)''', replace, text, re.M)


def inline_resources(root, base):
    for style in root.xpath('//style'):
        text = style.text
        if text and 'url(' in text:  # )
            style.text = inline_css_urls(text, base)
    for link in root.xpath('//link[@href]'):
        if link.get('rel', '') in ('stylesheet', ''):
            inline_attr(link, 'href', base)
    for script in root.xpath('//script[@src]'):
        inline_attr(script, 'src', base)
    for img in root.xpath('//img[@src]'):
        inline_attr(img, 'src', base)
    for x in root.xpath('//object[@data]'):
        inline_attr(x, 'data', base)

def main():
    os.chdir(os.path.dirname(self_path))

    for x in glob.glob('*/talk.html'):
        with open(x, 'rb') as f:
            raw = f.read()
        dest = os.path.join(os.path.dirname(x), 'index.html')
        if newer(dest, x):
            root = parse(raw)
            inline_resources(root, os.path.dirname(os.path.abspath(x)))
            nraw = tostring(root, encoding=str, doctype='<!doctype html>').encode('utf-8')
            if nraw != raw:
                with open(dest, 'wb') as f:
                    f.write(nraw)


if __name__ == '__main__':
    main()
